@inproceedings{kushnareva_artificial_2021,
  title     = {Artificial {Text} {Detection} via {Examining} the {Topology} of {Attention} {Maps}},
  url       = {http://arxiv.org/abs/2109.04825},
  doi       = {10.18653/v1/2021.emnlp-main.50},
  abstract  = {The impressive capabilities of recent generative models to create texts that are challenging to distinguish from the human-written ones can be misused for generating fake news, product reviews, and even abusive content. Despite the prominent performance of existing methods for artificial text detection, they still lack interpretability and robustness towards unseen models. To this end, we propose three novel types of interpretable topological features for this task based on Topological Data Analysis (TDA) which is currently understudied in the field of NLP. We empirically show that the features derived from the BERT model outperform count- and neural-based baselines up to 10{\textbackslash}\% on three common datasets, and tend to be the most robust towards unseen GPT-style generation models as opposed to existing methods. The probing analysis of the features reveals their sensitivity to the surface and syntactic properties. The results demonstrate that TDA is a promising line with respect to NLP tasks, specifically the ones that incorporate surface and structural information.},
  urldate   = {2024-05-16},
  booktitle = {Proceedings of the 2021 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
  author    = {Kushnareva, Laida and Cherniavskii, Daniil and Mikhailov, Vladislav and Artemova, Ekaterina and Barannikov, Serguei and Bernstein, Alexander and Piontkovskaya, Irina and Piontkovski, Dmitri and Burnaev, Evgeny},
  year      = {2021},
  note      = {arXiv:2109.04825 [cs, math]},
  keywords  = {read, add to obsidian},
  pages     = {635--649}
}
%[1] E. Katsadouros and C. Patrikakis, “A Survey on Vulnerability Prediction using GNNs,” in Proceedings of the 26th Pan-Hellenic Conference on Informatics, Athens Greece: ACM, Nov. 2022, pp. 38–43. doi: 10.1145/3575879.3575964.
%[2] A. Shestov, R. Levichev, R. Mussabayev, E. Maslov, A. Cheshkov, and P. Zadorozhny, “Finetuning Large Language Models for Vulnerability Detection.” arXiv, Mar. 01, 2024. doi: 10.48550/arXiv.2401.17010.
%[3] “Deep Learning Based Vulnerability Detection: Are We There Yet? | IEEE Journals & Magazine | IEEE Xplore”, Accessed: Jun. 03, 2024. [Online]. Available: https://ieeexplore.ieee.org/abstract/document/9448435

@misc{shestov_finetuning_2024,
  title     = {Finetuning {Large} {Language} {Models} for {Vulnerability} {Detection}},
  url       = {http://arxiv.org/abs/2401.17010},
  doi       = {10.48550/arXiv.2401.17010},
  abstract  = {This paper presents the results of finetuning large language models (LLMs) for the task of detecting vulnerabilities in source code. We leverage WizardCoder, a recent improvement of the state-of-the-art LLM StarCoder, and adapt it for vulnerability detection through further finetuning. To accelerate training, we modify WizardCoder's training procedure, also we investigate optimal training regimes. For the imbalanced dataset with many more negative examples than positive, we also explore different techniques to improve classification performance. The finetuned WizardCoder model achieves improvement in ROC AUC and F1 measures on balanced and imbalanced vulnerability datasets over CodeBERT-like model, demonstrating the effectiveness of adapting pretrained LLMs for vulnerability detection in source code. The key contributions are finetuning the state-of-the-art code LLM, WizardCoder, increasing its training speed without the performance harm, optimizing the training procedure and regimes, handling class imbalance, and improving performance on difficult vulnerability detection datasets. This demonstrates the potential for transfer learning by finetuning large pretrained language models for specialized source code analysis tasks.},
  urldate   = {2024-04-24},
  publisher = {arXiv},
  author    = {Shestov, Alexey and Levichev, Rodion and Mussabayev, Ravil and Maslov, Evgeny and Cheshkov, Anton and Zadorozhny, Pavel},
  month     = mar,
  year      = {2024},
  note      = {arXiv:2401.17010 [cs]
               version: 4},
  keywords  = {learning, read, llms},
  file      = {arXiv Fulltext PDF:/Users/snopoff/Zotero/storage/8HFQSQFK/Shestov et al. - 2024 - Finetuning Large Language Models for Vulnerability.pdf:application/pdf;arXiv.org Snapshot:/Users/snopoff/Zotero/storage/EG325T2C/2401.html:text/html}
}

@inproceedings{katsadouros_survey_2022,
  address   = {Athens Greece},
  title     = {A {Survey} on {Vulnerability} {Prediction} using {GNNs}},
  isbn      = {978-1-4503-9854-1},
  url       = {https://dl.acm.org/doi/10.1145/3575879.3575964},
  doi       = {10.1145/3575879.3575964},
  language  = {en},
  urldate   = {2024-04-24},
  booktitle = {Proceedings of the 26th {Pan}-{Hellenic} {Conference} on {Informatics}},
  publisher = {ACM},
  author    = {Katsadouros, Evangelos and Patrikakis, Charalampos},
  month     = nov,
  year      = {2022},
  keywords  = {learning, read},
  pages     = {38--43},
  file      = {Full Text:/Users/snopoff/Zotero/storage/INE29LFJ/Katsadouros and Patrikakis - 2022 - A Survey on Vulnerability Prediction using GNNs.pdf:application/pdf}
}

@article{saikat_chakraborty_deep_2022,
  title    = {Deep {Learning} {Based} {Vulnerability} {Detection}: {Are} {We} {There} {Yet}? {\textbar} {IEEE} {Journals} \& {Magazine} {\textbar} {IEEE} {Xplore}},
  url      = {https://ieeexplore.ieee.org/abstract/document/9448435},
  urldate  = {2024-06-03},
  author   = {{Saikat Chakraborty} and {Rahul Krishna} and {Yangruibo Ding} and {Baishakhi Ray}},
  month    = sep,
  year     = {2022},
  keywords = {reading},
  file     = {Deep Learning Based Vulnerability Detection Are W.pdf:/Users/snopoff/Zotero/storage/39UVNBX6/Deep Learning Based Vulnerability Detection Are W.pdf:application/pdf}
}

@article{aggarwal_dory_2024,
  title      = {Dory: {Computation} of persistence diagrams up to dimension two for {Vietoris}–{Rips} filtrations of large data sets},
  volume     = {79},
  issn       = {1877-7503},
  shorttitle = {Dory},
  url        = {https://www.sciencedirect.com/science/article/pii/S1877750324000838},
  doi        = {10.1016/j.jocs.2024.102290},
  abstract   = {Persistent homology (PH) is an approach to topological data analysis (TDA) that computes multi-scale topologically invariant properties of high-dimensional data that are robust to noise. While PH has revealed useful patterns across various applications, computational requirements have limited applications to small data sets of a few thousand points. We present Dory, an efficient and scalable algorithm that can compute the persistent homology of sparse Vietoris–Rips complexes on larger data sets, up to and including dimension two and over the field Z2. As an application, we compute the PH of the human genome at high resolution as revealed by a genome-wide Hi-C data set containing approximately three million points. Extant algorithms were unable to process it, whereas Dory processed it within five minutes, using less than five GB of memory. Results show that the topology of the human genome changes significantly upon treatment with auxin, a molecule that degrades cohesin, corroborating the hypothesis that cohesin plays a crucial role in loop formation in DNA.},
  urldate    = {2024-05-03},
  journal    = {Journal of Computational Science},
  author     = {Aggarwal, Manu and Periwal, Vipul},
  month      = jul,
  year       = {2024},
  keywords   = {persistence},
  pages      = {102290},
  file       = {Aggarwal and Periwal - 2024 - Dory Computation of persistence diagrams up to di.pdf:/Users/snopoff/Zotero/storage/CPNSF3EW/Aggarwal and Periwal - 2024 - Dory Computation of persistence diagrams up to di.pdf:application/pdf;ScienceDirect Snapshot:/Users/snopoff/Zotero/storage/RDUFJWEC/S1877750324000838.html:text/html}
}

@misc{steenhoek_comprehensive_2024,
  title     = {A {Comprehensive} {Study} of the {Capabilities} of {Large} {Language} {Models} for {Vulnerability} {Detection}},
  url       = {http://arxiv.org/abs/2403.17218},
  doi       = {10.48550/arXiv.2403.17218},
  abstract  = {Large Language Models (LLMs) have demonstrated great potential for code generation and other software engineering tasks. Vulnerability detection is of crucial importance to maintaining the security, integrity, and trustworthiness of software systems. Precise vulnerability detection requires reasoning about the code, making it a good case study for exploring the limits of LLMs' reasoning capabilities. Although recent work has applied LLMs to vulnerability detection using generic prompting techniques, their full capabilities for this task and the types of errors they make when explaining identified vulnerabilities remain unclear. In this paper, we surveyed eleven LLMs that are state-of-the-art in code generation and commonly used as coding assistants, and evaluated their capabilities for vulnerability detection. We systematically searched for the best-performing prompts, incorporating techniques such as in-context learning and chain-of-thought, and proposed three of our own prompting methods. Our results show that while our prompting methods improved the models' performance, LLMs generally struggled with vulnerability detection. They reported 0.5-0.63 Balanced Accuracy and failed to distinguish between buggy and fixed versions of programs in 76\% of cases on average. By comprehensively analyzing and categorizing 287 instances of model reasoning, we found that 57\% of LLM responses contained errors, and the models frequently predicted incorrect locations of buggy code and misidentified bug types. LLMs only correctly localized 6 out of 27 bugs in DbgBench, and these 6 bugs were predicted correctly by 70-100\% of human participants. These findings suggest that despite their potential for other tasks, LLMs may fail to properly comprehend critical code structures and security-related concepts. Our data and code are available at https://figshare.com/s/78fe02e56e09ec49300b.},
  urldate   = {2024-04-24},
  publisher = {arXiv},
  author    = {Steenhoek, Benjamin and Rahman, Md Mahbubur and Roy, Monoshi Kumar and Alam, Mirza Sanjida and Barr, Earl T. and Le, Wei},
  month     = mar,
  year      = {2024},
  note      = {arXiv:2403.17218 [cs]},
  keywords  = {learning, want to read, llms},
  file      = {arXiv Fulltext PDF:/Users/snopoff/Zotero/storage/L2DFUNR7/Steenhoek et al. - 2024 - A Comprehensive Study of the Capabilities of Large.pdf:application/pdf;arXiv.org Snapshot:/Users/snopoff/Zotero/storage/HP5BZB3Y/2403.html:text/html}
}

@misc{wen_vulnerability_2023,
  title     = {Vulnerability {Detection} with {Graph} {Simplification} and {Enhanced} {Graph} {Representation} {Learning}},
  url       = {http://arxiv.org/abs/2302.04675},
  doi       = {10.48550/arXiv.2302.04675},
  abstract  = {Prior studies have demonstrated the effectiveness of Deep Learning (DL) in automated software vulnerability detection. Graph Neural Networks (GNNs) have proven effective in learning the graph representations of source code and are commonly adopted by existing DL-based vulnerability detection methods. However, the existing methods are still limited by the fact that GNNs are essentially difficult to handle the connections between long-distance nodes in a code structure graph. Besides, they do not well exploit the multiple types of edges in a code structure graph (such as edges representing data flow and control flow). Consequently, despite achieving state-of-the-art performance, the existing GNN-based methods tend to fail to capture global information (i.e., long-range dependencies among nodes) of code graphs. To mitigate these issues, in this paper, we propose a novel vulnerability detection framework with grAph siMplification and enhanced graph rePresentation LEarning, named AMPLE. AMPLE mainly contains two parts: 1) graph simplification, which aims at reducing the distances between nodes by shrinking the node sizes of code structure graphs; 2) enhanced graph representation learning, which involves one edge-aware graph convolutional network module for fusing heterogeneous edge information into node representations and one kernel-scaled representation module for well capturing the relations between distant graph nodes. Experiments on three public benchmark datasets show that AMPLE outperforms the state-of-the-art methods by 0.39\%-35.32\% and 7.64\%-199.81\% with respect to the accuracy and F1 score metrics, respectively. The results demonstrate the effectiveness of AMPLE in learning global information of code graphs for vulnerability detection.},
  urldate   = {2024-04-24},
  publisher = {arXiv},
  author    = {Wen, Xin-Cheng and Chen, Yupan and Gao, Cuiyun and Zhang, Hongyu and Zhang, Jie M. and Liao, Qing},
  month     = feb,
  year      = {2023},
  note      = {arXiv:2302.04675 [cs]},
  file      = {arXiv Fulltext PDF:/Users/snopoff/Zotero/storage/KV598PS2/Wen et al. - 2023 - Vulnerability Detection with Graph Simplification .pdf:application/pdf;arXiv.org Snapshot:/Users/snopoff/Zotero/storage/QYAVYMS5/2302.html:text/html}
}

@misc{steenhoek_empirical_2023,
  title     = {An {Empirical} {Study} of {Deep} {Learning} {Models} for {Vulnerability} {Detection}},
  url       = {http://arxiv.org/abs/2212.08109},
  doi       = {10.48550/arXiv.2212.08109},
  abstract  = {Deep learning (DL) models of code have recently reported great progress for vulnerability detection. In some cases, DL-based models have outperformed static analysis tools. Although many great models have been proposed, we do not yet have a good understanding of these models. This limits the further advancement of model robustness, debugging, and deployment for the vulnerability detection. In this paper, we surveyed and reproduced 9 state-of-the-art (SOTA) deep learning models on 2 widely used vulnerability detection datasets: Devign and MSR. We investigated 6 research questions in three areas, namely model capabilities, training data, and model interpretation. We experimentally demonstrated the variability between different runs of a model and the low agreement among different models' outputs. We investigated models trained for specific types of vulnerabilities compared to a model that is trained on all the vulnerabilities at once. We explored the types of programs DL may consider "hard" to handle. We investigated the relations of training data sizes and training data composition with model performance. Finally, we studied model interpretations and analyzed important features that the models used to make predictions. We believe that our findings can help better understand model results, provide guidance on preparing training data, and improve the robustness of the models. All of our datasets, code, and results are available at https://doi.org/10.6084/m9.figshare.20791240.},
  urldate   = {2024-04-28},
  publisher = {arXiv},
  author    = {Steenhoek, Benjamin and Rahman, Md Mahbubur and Jiles, Richard and Le, Wei},
  month     = feb,
  year      = {2023},
  note      = {arXiv:2212.08109 [cs]},
  file      = {arXiv Fulltext PDF:/Users/snopoff/Zotero/storage/BPMLWVC3/Steenhoek et al. - 2023 - An Empirical Study of Deep Learning Models for Vul.pdf:application/pdf;arXiv.org Snapshot:/Users/snopoff/Zotero/storage/TAGKFPG3/2212.html:text/html}
}

@misc{guo_graphcodebert_2021,
  title      = {{GraphCodeBERT}: {Pre}-training {Code} {Representations} with {Data} {Flow}},
  shorttitle = {{GraphCodeBERT}},
  url        = {http://arxiv.org/abs/2009.08366},
  doi        = {10.48550/arXiv.2009.08366},
  abstract   = {Pre-trained models for programming language have achieved dramatic empirical improvements on a variety of code-related tasks such as code search, code completion, code summarization, etc. However, existing pre-trained models regard a code snippet as a sequence of tokens, while ignoring the inherent structure of code, which provides crucial code semantics and would enhance the code understanding process. We present GraphCodeBERT, a pre-trained model for programming language that considers the inherent structure of code. Instead of taking syntactic-level structure of code like abstract syntax tree (AST), we use data flow in the pre-training stage, which is a semantic-level structure of code that encodes the relation of "where-the-value-comes-from" between variables. Such a semantic-level structure is neat and does not bring an unnecessarily deep hierarchy of AST, the property of which makes the model more efficient. We develop GraphCodeBERT based on Transformer. In addition to using the task of masked language modeling, we introduce two structure-aware pre-training tasks. One is to predict code structure edges, and the other is to align representations between source code and code structure. We implement the model in an efficient way with a graph-guided masked attention function to incorporate the code structure. We evaluate our model on four tasks, including code search, clone detection, code translation, and code refinement. Results show that code structure and newly introduced pre-training tasks can improve GraphCodeBERT and achieves state-of-the-art performance on the four downstream tasks. We further show that the model prefers structure-level attentions over token-level attentions in the task of code search.},
  urldate    = {2024-06-03},
  publisher  = {arXiv},
  author     = {Guo, Daya and Ren, Shuo and Lu, Shuai and Feng, Zhangyin and Tang, Duyu and Liu, Shujie and Zhou, Long and Duan, Nan and Svyatkovskiy, Alexey and Fu, Shengyu and Tufano, Michele and Deng, Shao Kun and Clement, Colin and Drain, Dawn and Sundaresan, Neel and Yin, Jian and Jiang, Daxin and Zhou, Ming},
  month      = sep,
  year       = {2021},
  note       = {arXiv:2009.08366 [cs]},
  file       = {arXiv Fulltext PDF:/Users/snopoff/Zotero/storage/5SD3WQ3S/Guo et al. - 2021 - GraphCodeBERT Pre-training Code Representations w.pdf:application/pdf;arXiv.org Snapshot:/Users/snopoff/Zotero/storage/XKKLNHF7/2009.html:text/html}
}

@article{sharma_survey_2024,
  title    = {A survey on machine learning techniques applied to source code},
  volume   = {209},
  issn     = {0164-1212},
  url      = {https://www.sciencedirect.com/science/article/pii/S0164121223003291},
  doi      = {10.1016/j.jss.2023.111934},
  abstract = {The advancements in machine learning techniques have encouraged researchers to apply these techniques to a myriad of software engineering tasks that use source code analysis, such as testing and vulnerability detection. Such a large number of studies hinders the community from understanding the current research landscape. This paper aims to summarize the current knowledge in applied machine learning for source code analysis. We review studies belonging to twelve categories of software engineering tasks and corresponding machine learning techniques, tools, and datasets that have been applied to solve them. To do so, we conducted an extensive literature search and identified 494 studies. We summarize our observations and findings with the help of the identified studies. Our findings suggest that the use of machine learning techniques for source code analysis tasks is consistently increasing. We synthesize commonly used steps and the overall workflow for each task and summarize machine learning techniques employed. We identify a comprehensive list of available datasets and tools useable in this context. Finally, the paper discusses perceived challenges in this area, including the availability of standard datasets, reproducibility and replicability, and hardware resources. Editor’s note: Open Science material was validated by the Journal of Systems and Software Open Science Board.},
  urldate  = {2024-06-03},
  journal  = {Journal of Systems and Software},
  author   = {Sharma, Tushar and Kechagia, Maria and Georgiou, Stefanos and Tiwari, Rohit and Vats, Indira and Moazen, Hadi and Sarro, Federica},
  month    = mar,
  year     = {2024},
  keywords = {reading},
  pages    = {111934},
  file     = {Full Text:/Users/snopoff/Zotero/storage/XD55YZTD/Sharma et al. - 2024 - A survey on machine learning techniques applied to.pdf:application/pdf;ScienceDirect Snapshot:/Users/snopoff/Zotero/storage/7GYXAURB/S0164121223003291.html:text/html}
}

@inproceedings{zhou_devign_2019,
  title      = {Devign: {Effective} {Vulnerability} {Identification} by {Learning} {Comprehensive} {Program} {Semantics} via {Graph} {Neural} {Networks}},
  volume     = {32},
  shorttitle = {Devign},
  url        = {https://proceedings.neurips.cc/paper/2019/hash/49265d2447bc3bbfe9e76306ce40a31f-Abstract.html},
  abstract   = {Vulnerability identification is crucial to protect the software systems from attacks
                for cyber security. It is especially important to localize the vulnerable functions
                among the source code to facilitate the fix. However, it is a challenging and tedious
                process, and also requires specialized security expertise. Inspired by the work
                on manually-defined patterns of vulnerabilities from various code representation
                graphs and the recent advance on graph neural networks, we propose Devign, a
                general graph neural network based model for graph-level classification through
                learning on a rich set of code semantic representations. It includes a novel Conv
                module to efficiently extract useful features in the learned rich node representations for graph-level classification. The model is trained over manually labeled datasets built on 4 diversified large-scale open-source C projects that incorporate high complexity and variety of real source code instead of synthesis code used in previous works. The results of the extensive evaluation on the datasets demonstrate that Devign outperforms the state of the arts significantly with an average of 10.51\% higher accuracy and 8.68\% F1 score, increases averagely 4.66\% accuracy and 6.37\% F1 by the Conv module.},
  urldate    = {2024-06-03},
  booktitle  = {Advances in {Neural} {Information} {Processing} {Systems}},
  publisher  = {Curran Associates, Inc.},
  author     = {Zhou, Yaqin and Liu, Shangqing and Siow, Jingkai and Du, Xiaoning and Liu, Yang},
  year       = {2019},
  file       = {Full Text PDF:/Users/snopoff/Zotero/storage/PSME6PJF/Zhou et al. - 2019 - Devign Effective Vulnerability Identification by .pdf:application/pdf}
}

@misc{nguyen_regvd_2022,
  title      = {{ReGVD}: {Revisiting} {Graph} {Neural} {Networks} for {Vulnerability} {Detection}},
  shorttitle = {{ReGVD}},
  url        = {http://arxiv.org/abs/2110.07317},
  abstract   = {Identifying vulnerabilities in the source code is essential to protect the software systems from cyber security attacks. It, however, is also a challenging step that requires specialized expertise in security and code representation. To this end, we aim to develop a general, practical, and programming language-independent model capable of running on various source codes and libraries without difficulty. Therefore, we consider vulnerability detection as an inductive text classification problem and propose ReGVD, a simple yet effective graph neural network-based model for the problem. In particular, ReGVD views each raw source code as a flat sequence of tokens to build a graph, wherein node features are initialized by only the token embedding layer of a pre-trained programming language (PL) model. ReGVD then leverages residual connection among GNN layers and examines a mixture of graph-level sum and max poolings to return a graph embedding for the source code. ReGVD outperforms the existing state-of-the-art models and obtains the highest accuracy on the real-world benchmark dataset from CodeXGLUE for vulnerability detection. Our code is available at: {\textbackslash}url\{https://github.com/daiquocnguyen/GNN-ReGVD\}.},
  urldate    = {2024-04-24},
  publisher  = {arXiv},
  author     = {Nguyen, Van-Anh and Nguyen, Dai Quoc and Nguyen, Van and Le, Trung and Tran, Quan Hung and Phung, Dinh},
  month      = feb,
  year       = {2022},
  note       = {arXiv:2110.07317 [cs]},
  file       = {arXiv.org Snapshot:/Users/snopoff/Zotero/storage/9WIVBWBF/2110.html:text/html;Full Text PDF:/Users/snopoff/Zotero/storage/BK3YUAAC/Nguyen et al. - 2022 - ReGVD Revisiting Graph Neural Networks for Vulner.pdf:application/pdf}
}
