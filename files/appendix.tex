\begin{subappendices}
    \newpage
    \renewcommand{\thesection}{\Alph{section}}%
    \section{Training Details}
    \label{training_details}
    \subsubsection*{Fine-tuning CodeBERTa} We trained with the cosine scheduler 
    with an initial learning rate $\mathrm{lr}=5e-5$ and set the number of epochs $\mathrm{e}=15$.
    \subsubsection*{Hyperparameter search} We employed {\it Optuna} \cite{optuna} to 
    find optimal hyperparameters for both SVM and LightGBM models.
    
    For SVM, the optimal hyperparameters were
    $C=9.97$, $\gamma=\mathrm{auto}$ and $\mathrm{kernel}=\mathrm{rbf}$. 
    
    For LightGBM, the optimal parameters were
    $\lambda_{\ell_1}=5.97$, $\lambda_{\ell_2}=0.05$, $\mathrm{num\_leaves}=422$, $\mathrm{feature\_fraction}=0.65$,
    $\mathrm{bagging\_fraction}=0.93$, $\mathrm{bagging\_freq}=15$, $\mathrm{min\_child\_samples}=21$.
    \section{Persistent Homology}
    \label{persistent_homology}
    Recall that a simplicial complex $X$ is a collection of $p$-dimensional simplices, 
    i.e., vertices, edges, triangles, tetrahedrons, and so on. Simplicial complexes 
    generalize graphs, which consist of vertices ($0$-simplices) and edges 
    ($1$-simplices) and can represent higher-order interactions.
A family of increasing simplicial complexes

\[
\emptyset \subseteq X_0 \subseteq X_1 \subseteq \cdots \subseteq X_{n-1} \subseteq X_n
\]

is called a \textit{filtration}.

The idea of \textit{persistence} involves tracking the evolution of simplicial complexes over the filtration. 
{\it Persistent homology} allows to trace the changes in homology vector 
spaces\footnote{Usually, homology groups are considered with integral coefficients, but in the realm of 
persistence, homology groups are taken with coefficients in some field, for example, $\mathbb{Z}_p$ for some large prime number $p$. Hence, the homology groups become homology vector spaces.} of simplicial complexes 
that are present in the filtration. Given a filtration $\{X_t\}_{t=0}^n$, the homology functor $H_p$ applied 
to the filtration generates a sequence of vector spaces $H_p(X_t)$ and maps $i_*$ between them

\[
H_p(X_*): H_p(X_0) \xrightarrow{i_0} H_p(X_1) \xrightarrow{i_1} \cdots \xrightarrow{i_{n-1}} H_p(X_n).
\]

Each vector spaces encodes information about the simplicial complex $X$ and its 
subcomplexes $X_i$. For example, $H_0$ generally encodes the connectivity of the space 
(or, in data terms, $H_0$ encodes the clusters of data), $H_1$ encodes the presence of 1-cycles, i.e., loops, 
$H_2$ represents the presence of 2-cycles, and so on. Persistence tracks the generators of each 
vector space through the induced maps. Some generators will vanish, while others will persist. 
Those that persist are likely the most important, as they represent features that truly exist in $X$. 
Therefore, persistent homology allows one to gain information about the underlying topological space via 
the sequence of its subspaces, the filtration.

In algebraic terms, the sequence of vector spaces $H_p(X_t)$ and maps $i_*$ between them can be seen as a 
representation of a quiver $I_n$. From the representation theory of quivers 
it is known, due to Gabriel, that any such representation is isomorphic to a direct sum of indecomposable 
interval representations $I[b_i, d_i]$, that is,

\[
H_p(X_*) \simeq \bigoplus_i I[b_i, d_i].
\]

The pairs $(b_i, d_i)$ represent the persistence of topological features, where $b_i$ denotes the time of 
birth and $d_i$ denotes the time of death of the feature. These pairs can be visualized via {\it barcodes} 
where each bar starts at $b_i$ and ends at $d_i$.


This information is also commonly represented using {\it persistence diagrams}. A persistence diagram is a 
(multi)set of points in the extended plane $\overline{\mathbb{R}^2}$, which reflects the structure of persistent homology.
 Given a set of pairs $(b_i, d_i)$, each pair can be considered as a point in the diagram with coordinates $(b_i, d_i)$. Thus, a 
 persistence diagram is defined as

\[
\mathrm{dgm}(H_p(X_*)) = \{ (b_i, d_i) : I[b_i, d_i] \text{ is a direct summand in } H_p(X_*) \}.
\]

Persistence diagrams provide a detailed visual representation of the topology of 
point clouds. However, integrating them into machine learning models presents 
significant challenges due to their complex structure. To effectively use the 
information from persistence diagrams in predictive models, it is crucial to 
transform the data into a suitable format, such as by applying persistence entropy.

{\it Persistence entropy} is a  specialized form of Shannon entropy specially designed for persistence
diagrams and is calculated as follows:

\[
PE_k(X) \coloneqq -\sum_{(b_i, d_i) \in D_k} p_i \log(p_i),
\]

where

\[p_i = \frac{d_i - b_i}{\sum_{(b_i, d_i) \in D_k} (d_i - b_i)} \quad \text{and} \quad D_k \coloneqq \mathrm{dgm}(H_k(X_\bullet)).\]

This numerical characteristic of a persistence diagram has several advantageous 
properties. Notably, it is stable under certain mild assumptions. This stability means 
there is a bound that <<controls>> the perturbations caused by noise in the input data.
\end{subappendices}