Table \ref*{results} outlines the results of the vulnerability detection
experiments on the {\it Devign} dataset. The results reveal that the proposed topology-based
classifiers ourperform chosen LLM without fine-tuning but perform worse than the fine-tuned version.

\begin{table}
    \label{tab:results}
    \centering
    \caption{The results of the vulnerability detection experiments.}\label{results}
    \begin{tabular}{|c|c|c|}
    \hline
    {\bf Model} & {\bf F1 score} & {\bf Accuracy} \\
    \hline
    Logistic Regression & 0.22 & 0.54 \\
    \hline
    LightGBM & {\bf 0.55} & 0.63 \\
    \hline
    SVM & 0.54 & {\bf 0.65} \\
    \hline
    CodeBERTa (pre-trained) & 0.28 & 0.45 \\
    \hline
    CodeBERTa (fine-tuned) & {\bf 0.71} & 0.72 \\
    \hline
    \end{tabular}
\end{table}


This observation shows that the information about the code snippet being vulnerable is encoded
in the topological attributes of the attention matrices. The semantic evolution in the attention
heads reflects the code properties that happen to be important in the vulnerability detection task.
And persistent homology appears to be a suitable method for extracting this information.

Notice that only the semantic information from attention heads was used. The use of additional
topological features obtained from the structural information of the source code, such as the 
topology of the graph representations of the source code, might probably increase the overall
quality of the proposed models.