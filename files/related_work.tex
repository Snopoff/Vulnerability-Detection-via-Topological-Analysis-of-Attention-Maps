This work resembles \cite{kushnareva_artificial_2021} and uses its techniques for the vulnerability detection task. This work is an attempt to apply TDA methods over the transformer modelâ€™s attention maps and interpret topological features for the NLP field. This is the first work applying TDA methods for the vulnerability detection task.

Another works on vulnerability detection via LLMs and GNNs.

By our knowledge, this is the first work that leverages the methods from topological data analysis
in the vulnerability detection task.

But recently the different ML-based and DL-based methods started to
appear \cite{sharma_survey_2024,steenhoek_empirical_2023}. 
Most DL-based solutions provide the methods based on graph neural networks (GNNs) \cite{wen_vulnerability_2023,nguyen_regvd_2022,zhou_devign_2019}.
Besides GNN-based models, there exists LLM-based approaches \cite{shestov_finetuning_2024,steenhoek_comprehensive_2024,guo_graphcodebert_2021}. 
Both GNN-based and LLM-based methods are targeted to learn the semantics together with the syntax 
of the program. This approaches show the promising results, in particular such methods demonstrate 
low rates of false positives as well as false negatives \cite{katsadouros_survey_2022}.

However some studies show that the generalization of DL-based methods is very poor, and that 
there are no existing models that would perform well in real-world settings \cite{saikat_chakraborty_deep_2022}. 
This situation shows that there is still no silver bullet for the vulnerability detection task. 
