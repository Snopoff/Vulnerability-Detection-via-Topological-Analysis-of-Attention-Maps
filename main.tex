\documentclass{llncs}
\usepackage{graphicx} % Required for inserting images
\usepackage[T1]{fontenc}
\usepackage[utf8x]{inputenc}
%\usepackage[russian]{babel}

\def\keywordname{{\bf Keywords:}}%

\title{Vulnerability Detection via Topological Analysis of Attention Maps}
\author{Snopov P. \inst{1},
Golubinsky A.N.\inst{1}}

\institute{Institute for Information Transmission Problems of Russian Academy of Sciences
%Институт проблем передачи информации им. А.А. Харкевича РАН, 127051, г.Москва, Б. Каретный пер., д.19, стр.1 \and
\email{snopov@iitp.ru}\\
}

\usepackage{biblatex}
\addbibresource{biblio.bib}

\begin{document}

\maketitle
\begin{abstract}
    Recently, DL-based approaches to the vulnerability detection task became 
    popular. They show promising results, outperforming traditional static 
    code analysis tools. 

    In this work, we test a novel approach to the vulnerability detection using
    topological data analysis of the attention matrices of BERT model. 
    We show that
    %Аннотация должна кратко излагать содержание статьи, не более 150-250 слов.
    
    \keywords{Vulnerability detection, Persistent homology, Large language models}
    \end{abstract}

\section{Introduction}
\input{files/introduction.tex}
%\section{Related Work}
%\input{files/related_work.tex}
%This work resembles \cite{kushnareva_artificial_2021} and uses its techniques for the vulnerability detection task. This work is an attempt to apply TDA methods over the transformer model’s attention maps and interpret topological features for the NLP field. This is the first work applying TDA methods for the vulnerability detection task.
\section{Background}
\input{files/background.tex}
\section{Topological Features of the Attention Graphs}
\input{files/topological_features.tex}
\section{Experiments}
\input{files/experiments.tex}
\section{Discussion}
\input{files/discussion.tex}
\section{Consclusion}
\input{files/conclusion.tex}
\printbibliography[title={Bibliography}]

\end{document}
