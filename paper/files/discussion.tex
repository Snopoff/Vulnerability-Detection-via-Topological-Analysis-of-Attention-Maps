Table \ref*{results} outlines the results of the vulnerability detection experiments 
on the {\it Devign} dataset. The results reveal that the proposed topology-based 
classifiers outperform the chosen large language model (LLM) without fine-tuning but 
perform worse than the fine-tuned version.

\begin{table}
    \label{tab:results}
    \centering
    \caption{The results of the vulnerability detection experiments.}\label{results}
    \begin{tabular}{|c|c|c|}
    \hline
    {\bf Model} & {\bf F1 score} & {\bf Accuracy} \\
    \hline
    Logistic Regression & 0.22 & 0.54 \\
    \hline
    LightGBM & {\bf 0.55} & 0.63 \\
    \hline
    SVM & 0.54 & {\bf 0.65} \\
    \hline
    CodeBERTa (pre-trained) & 0.28 & 0.45 \\
    \hline
    CodeBERTa (fine-tuned) & {\bf 0.71} & {\bf 0.72} \\
    \hline
    \end{tabular}
\end{table}


These observations indicate that the information about a code snippet's vulnerability 
is encoded in the topological attributes of the attention matrices. The semantic 
evolution in the attention heads reflects code properties that are crucial for the 
vulnerability detection task, and persistent homology proves to be an effective method 
for extracting this information.

Notably, only the semantic information from attention heads was used. 
The inclusion of additional topological features obtained from the structural 
information of the source code, such as the topology of graph representations of the 
source code, could potentially enhance the overall performance of the proposed models.