\documentclass[runningheads]{llncs}
\usepackage{graphicx} % Required for inserting images
\usepackage[T1]{fontenc}
\usepackage[utf8x]{inputenc}
\usepackage[english]{babel}

\def\keywordname{{\bf Keywords:}}%

\title{Vulnerability Detection via Topological Analysis of Attention Maps}
\author{Pavel Snopov \inst{1}}

\institute{Institute for Information Transmission Problems of Russian Academy of Sciences}

\begin{document}

\maketitle
Recently, DL-based approaches to the vulnerability detection task became 
popular. They show promising results, outperforming traditional static 
code analysis tools. In this work, we test a novel approach to the vulnerability detection using
topological data analysis of the attention matrices of pretrained on code LLMs. 
We choose \texttt{microsoft/codebert-base} as our base model.

For each code sample, we calculate the persistent homology in dimension $0$ and $1$ 
of the symmetrized attention matrices, obtaining the persistence diagram on each 
attention head of the BERT model. We compute the following features in each dimension 
from the diagrams:
\begin{itemize}
    \item The mean lifespan of points on the diagram
    \item The variance lifespan of points on the diagram
    \item The max lifespan of points on the diagram
    \item The overall number of points on the diagram
    \item The persistence entropy
\end{itemize}

We symmetrize attention matrices in the following manner: 
\begin{equation}
    \forall i,j: W^\mathrm{sym}_{ij} = \max{(W_{ij}^\mathrm{attn}, W_{ji}^\mathrm{attn})}.
\end{equation}

We consider these features as the numerical characteristic of the semantic evolution processes 
in the attention heads. The features with <<significant>> persistence (i.e. those with large lifespan) 
correspond to the stable processes, whileas the features with short lifespan are highly influenced 
to noise and doesn't reflect the stable topological attributes.

\begin{table}
    \label{tab:results}
    \centering
    \caption{The results of the vulnerability detection experiments.}\label{results}
    \begin{tabular}{|c|c|c|}
    \hline
    {\bf Model} & {\bf F1 score} & {\bf Accuracy} \\
    \hline
    Logistic Regression & 0.22 & 0.54 \\
    \hline
    LightGBM & {\bf 0.55} & 0.63 \\
    \hline
    SVM & 0.54 & {\bf 0.65} \\
    \hline
    CodeBERTa (pre-trained) & 0.28 & 0.45 \\
    \hline
    CodeBERTa (fine-tuned) & {\bf 0.55} & 0.55 \\
    \hline
    \end{tabular}
\end{table}

Table \ref*{tab:results} outlines the results of the vulnerability detection
experiments on the {\it Devign} dataset. The results reveal that the proposed topology-based
classifiers ourperform chosen LLM without fine-tuning and perform on par with the fine-tuned version.
\bibliographystyle{splncs04}
\bibliography{biblio}

\end{document}
